{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CSVs Into Postgres Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous notebook entitled *extract_option_price_data` I grabbed temporary small CSVs for each underlying/trade-date combination in my universe.  In this notebook I import all of those CSVs into a database table called `option_price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Connection to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# creating connection and cursor objects\n",
    "conn = psycopg2.connect(\n",
    "    host = \"localhost\",\n",
    "    database = \"delta_neutral\",\n",
    "    user = \"postgres\",\n",
    "    password = \"$3lfl0v3\",\n",
    "    port = 5432,\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the `option_price` Table if it Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping option_price table if it exists\n",
    "str_sql = \\\n",
    "    \"drop table if exists option_price\"\n",
    "cur.execute(str_sql)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the `option_price` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script for creating the table is in a file called *create_option_price_table.sql*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "file_sql = open(\"create_option_price_table.sql\", 'r')\n",
    "lst_sql = file_sql.readlines()\n",
    "str_sql = \"\"\n",
    "for ix_line in lst_sql:\n",
    "    str_sql = str_sql + ix_line + \" \"\n",
    "cur.execute(str_sql)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing All The Underlyings in the Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly = pd.read_csv(\"weekly_underlyings_20210405.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a List of All the Temp File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# getting list of all CSVs\n",
    "lst_path_all = []\n",
    "#underlyings = ['SPY', 'IWM', 'GLD', 'SLV', 'QQQ']\n",
    "underlyings = df_weekly['ticker']\n",
    "for ix_underlying in underlyings:\n",
    "    underlying_path = '/home/pritam/files/data/delta_neutral/temp/option_price/*_' + ix_underlying.lower() + '_options.csv'\n",
    "    #print(underlying_path)\n",
    "    lst_path_underlying = glob.glob(underlying_path)\n",
    "    lst_path_underlying.sort()\n",
    "    lst_path_all.extend(lst_path_underlying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360220"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_path_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through All the Paths and Importing the Files into `option_price` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# iterating through CSVs and loading each with COPY statement\n",
    "ix = 1\n",
    "for ix_path in lst_path_all:\n",
    "    #print(ix)\n",
    "    ix = ix + 1\n",
    "    #print(ix_path)\n",
    "    str_sql = \\\n",
    "        \"copy option_price from \" + \\\n",
    "        \"'\" + ix_path + \"' \" + \\\n",
    "        \"delimiter ',' csv header;\"\n",
    "    cur.execute(str_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    if (ix % 10000) == 0:\n",
    "        print(ix)\n",
    "        time.sleep(30)\n",
    "\n",
    "#%%\n",
    "# creating stock_quotes table\n",
    "conn.close()\n",
    "print(\"DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
